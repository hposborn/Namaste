'''
This module runs the MCMC code on any single transit, 

Inputs:
   Name of object
   Lightcurve fits file location
   Initial estimates of lightcurve parameters
   Photometric colours OR directly determined input stellar parameters

Outputs the median value and errors for:
   Time of transit, Tcen
   Orbital Velocity, v
   Impact Parameter, b
   Planet to Star ratio, r
   Stellar flux level, F
And saves a triangle plot, output values and ''sampler'' file to disc
'''

import numpy as np
import pandas as pd
import glob
import pylab as p
#import me.planetlib as pl
from StellarFits import *
from Monotransit import *
from planetlib import *
import scipy.optimize as optimize
import emcee
from os import sys, path
import csv
import pylab as p

#Getting working directory of Namaste
Namwd = path.dirname(path.realpath(__file__))
    
def Run(KIC, guess, nstep=20000, StarDat=[], lc=[], test=0):
    '''
    INPUTS:
    KIC as EPIC (K2) or KIC (Kepler) identifier
    guess as list of [Tcen, Tdur, depth]
    nstep: number of steps in MCMC (default 20000)
    StarDat in format Ts,eTs1,eTs2,Rs,eRs1,eRs2,Ms,eMs1,eMs2.
    If stardat empty, looks for stellar parameter estimates from EPIC/KIC catalogue
    lc is input lightcurve in format time, normalised flux and flux errors. If [], gets the lightcurve from either a directory or online
    test displays extra plots and text during MCMC run
    '''
    #Where params is Tcen (d), Tdur (d) and depth (frac)
    if lc==[]:
        lc=getKeplerLC(KIC)
    if guess==[]:
        guess=FindTransitManual(kic, lc, cut=25.0)
    NoPrevious=True
    if path.isfile(Namwd+'/Outputs/'+"sampler.npy"):
        #Found previous file. Using this instead of guess
        NoPrevious=False
        sams=np.load(Namwd+'/Outputs/'+"sampler.npy")
        sams[:, 1]=abs(sams[:, 1])
        #Taking last 4000 values in case previous run was poorly burned in
        params=np.median(sams[-4000:, :], axis=0)
        Tdur=(2*(1+params[3])*np.sqrt(1-(params[1]/(1+params[3]))**2))/params[2]
        Tdur=CalcTdur(np.median(sams[:,2]),np.median(sams[:,1]),np.median(sams[:,3]))
        Tcen=params[0]
        ratio=params[2]
        bestparams=params
        print 'Found Old Params for '+str(KIC)
    else:
        NoPrevious=True
        Tcen=guess[0]
        Tdur=guess[1]
        ratio=guess[2]**0.5
    if StarDat==[]:
        StarDat=getStarDat(KIC)
    
    #Getting Quadratic Limb Darkening Paramters from Temperature:
    #print T[0]
    #print "errors: "+str(T[1])+" | "+str(T[2])
    print str(KIC)+": Temperature and errors: "+str(StarDat[0]) 
    LD=getKeplerLDs(StarDat[0])
    if str(int(KIC)).zfill(9)[0]=='2':
        #Liminiting errors to 150K in temperature
        StarDat[1]=150 if StarDat[1]<150 else StarDat[1]
        StarDat[2]=150 if StarDat[2]<150 else StarDat[2]
    LDRange=np.array([getKeplerLDs(StarDat[0]+StarDat[1]), getKeplerLDs(StarDat[0]-StarDat[2])])
    #Getting Lightcurve

    #anom=np.where(np.round(lc[:, 0], 2)==575.33)[0]
    #if list(anom)!=[]:
    #    lc=np.vstack((lc[:anom],lc[(anom+1):]))
    #if type(hdr)!=str:
    #import me.k2flatten as k2f
    #if Tdur<0.8:
    lc=lc[np.where(abs(lc[:, 0]-Tcen)<Tdur*15.0)[0]]

    lc=k2f(lc, stepsize=Tdur/2.0, winsize=Tdur*8.5,  niter=40)
    #Flattening
    #outlc=lc[abs(lc[:, 0]-Tcen)>0.6*Tdur, :]
    #np.polyval(lc[:, 0], np.polyfit(outlc[:, 0], outlc[:, 1], 
    #Cutting lightcurve around transit
    lccut=lc[np.where(abs(lc[:, 0]-Tcen)<Tdur*6.0)[0]]
    #Guesing b as 0.4 to begin with.    
    #params=[  2.12101887e+03,   6.31623933e-01,   3.23164855e+00,5.72288968e-02,   1.00037038e+00,   4.93866558e-01,1.89379790e-01]
    if NoPrevious:
        params=[Tcen, 0.4, CalcVel(Tdur, 0.4, ratio), ratio, np.median(lccut[abs(lccut[:, 0]-Tcen)>1.1*Tdur, 1]), LD[0],  LD[1]]
        bestparams=np.array(params, copy=True)
    if test==1:
        PlotLC(lccut)
        p.plot(np.arange(lccut[0, 0], lccut[-1, 0], 0.001), modelmonotransit(params, np.arange(lccut[0, 0], lccut[-1, 0], 0.001)))
        p.title('Initial Fit with'+str(params))
        #p.pause(5)
        #p.clf()
    
    '''
        Params are:
        the time of conjunction for each individual transit (Tc),  0.1
        the impact parameter (b = a cos i/Rstar)  0.5
        vel -- scalar. planetary perpendicular velocity (in units of stellar radii per day) 1
        planet-to-star radius ratio (Rp/Rstar),  0.03
        stellar flux (F0),   0.001
        the limb-darkening parameters u1 and u2   0.1
    '''
    bestparams=np.array(params, copy=True)
    #For each value in params
    #Last two values now gaussian priors for limb darkening params:
    uniformprior=[[bestparams[0]-2*Tdur, bestparams[0]+2*Tdur], [-1.2, 1.2], [0.0, CalcVel(Tdur*0.95, 0.0, 0.3)], [0, 0.3], [0.95, 1.05], [LD[0], np.max(abs(LD[0]-LDRange[:, 0]))], [LD[1], np.max(abs(LD[1]-LDRange[:, 1]))]]
    
    print uniformprior
    
    ndim = len(params)
    covar = np.zeros((ndim, ndim), dtype=float)
    diag=np.zeros((ndim), dtype=float)
    for ii in range(ndim):
        covar[ii,ii] = 0.35*(abs(bestparams[ii]-uniformprior[ii][0])+abs(bestparams[ii]-uniformprior[ii][1]))
        diag[ii]=0.35*(abs(bestparams[ii]-uniformprior[ii][0])+abs(bestparams[ii]-uniformprior[ii][1]))
    print diag
    goodind = np.isfinite(lccut[:, 1])
    weights = np.array(lccut[:, 2]**-2, copy=True)
    fitkw = dict(uniformprior=uniformprior)    
    fitargs = (modelmonotransit, lccut[:, 0], lccut[:, 1], weights, fitkw) #time, NL, NP, errscale, smallplanet, svs, data, weights, fitkw)
    #fitargs = (modelmonotransit, lccut[:, 0], lccut[:, 1], lccut[:, 2], fitkw)
    xtol=1e-12
    ftol=1e-10
    if test==1:
        print 'Initial params: '+str(params)
        p.pause(1)
        print 'doing lsq fit with dvfuncup:'
    '''
    if NoPrevious:
        lsq_fit = optimize.minimize(lnprobfunc2, bestparams, args=fitargs)
        #optimize.minimize(lnprobfunc2, bestparams, args=fitargs, method='Nelder-Mead')#, diag=0.4*diag)
        bestparams = lsq_fit['x']
        print params/bestparams
        if test==1:
            #pl.PlotLC(lccut)
            p.plot(np.arange(lccut[0, 0], lccut[-1, 0], 0.001), modelmonotransit(bestparams, np.arange(lccut[0, 0], lccut[-1, 0], 0.001)))
            #p.title('New Best Fit with'+str(bestparams))
            p.pause(1)
        #lsq_fit = optimize.minimize(lnprobfunc2,  bestparams, args=fitargs)#, diag=0.2*diag)
        #bestparams = lsq_fit['x']
        #print params/bestparams
        if test==1:
            #pl.PlotLC(lccut)
            p.plot(np.arange(lccut[0, 0], lccut[-1, 0], 0.001), modelmonotransit(bestparams, np.arange(lccut[0, 0], lccut[-1, 0], 0.001)))
            #p.title('New Best Fit with'+str(bestparams))
            p.pause(1)
            '''
#        lsq_fit = optimize.fmin(lnprobfunc2, bestparams, args=fitargs)#, diag=0.2*diag)
#        bestparams = lsq_fit
#        print params/bestparams
#        print bestparams
#        if test==1:
#            #pl.PlotLC(lccut)
#            p.plot(np.arange(lccut[0, 0], lccut[-1, 0], 0.001), modelmonotransit(bestparams, np.arange(lccut[0, 0], lccut[-1, 0], 0.001)))
#            #p.title('New Best Fit with'+str(bestparams))
#            p.pause(5)
#            p.clf()
    
    bestchisq = errfunc(bestparams, *fitargs)
    #Setting parameters as defaults from Ian.transit

    nwalkers =20 * ndim
    nthread=4
    #nstep=700

    #print 'params:'
    print str(KIC)+": parameters:"+str(bestparams)
    #print (bestparams/100.)**2
    # Initialize sampler:
    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprobfunc, args=fitargs, threads=4)
    # Pick walker starting positions, excluding bad points:
    #print covar
    #print np.shape(covar)
    #print 'Covar ^. p0 vv'
    
    p0 = np.random.multivariate_normal(bestparams, covar, nwalkers*5)
    badp0 = ((abs(p0[:,1]) >1.5) + (p0[:,2] < 0) + (p0[:,3] < 0) + (p0[:,4] < 0))
    #print 'Number of bad p0s: '+str(len(np.nonzero(True-badp0)[0]))+' Number of p0s:'+str(len(p0[0]))
    p0 = np.vstack((bestparams, p0[np.nonzero(True-badp0)[0][0:nwalkers-1]]))
    #print 'Number of bad p0s: '+str(len(np.nonzero(True-badp0)[0]))+' Number of p0s:'+str(len(p0[0]))
    #print p0
    # Run burn-in; exclude and remove bad walkers:
    pos = p0
    #if test==1:
    print 'pos results before first mcmc:'
    print 'Badpos identified '+str(np.shape(badp0))+' positions with probs less than the median prob'
    print str(np.median(pos[:, 0]))+' <median | Tcen | std > '+str(np.std(pos[:, 0]))
    print str(np.median(pos[:, 1]))+' <median | b | std > '+str(np.std(pos[:, 1]))
    print str(np.median(pos[:, 2]))+' <median | v | std > '+str(np.std(pos[:, 2]))
    print str(np.median(pos[:, 3]))+' <median | p | std > '+str(np.std(pos[:, 3]))
    print str(np.median(pos[:, 4]))+' <median | F0 | std > '+str(np.std(pos[:, 4]))
    print str(np.median(pos[:, 5]))+' <median | u1 | std > '+str(np.std(pos[:, 5]))
    print str(np.median(pos[:, 6]))+' <median | u2 | std > '+str(np.std(pos[:, 6]))
    for ii in range(2):
        pos, prob, state = sampler.run_mcmc(pos, max(1, (ii+1)*nstep/5))
        if (bestchisq + 2*max(prob)) > ftol: #-2*prob < bestchisq).any(): # Found a better fit! Optimize:
            #if verbose: print "Found a better fit; re-starting MCMC... (%1.8f, %1.8f)" % (bestchisq, (bestchisq + 2*max(prob)))
            print str(KIC)+" - Found a better fit; re-starting MCMC..."
            #pdb.set_trace()
            bestparams = pos[(prob==prob.max()).nonzero()[0][0]].copy()
            lsq_fit = optimize.leastsq(devfuncup, bestparams, args=fitargs, full_output=True, xtol=xtol, ftol=ftol)
            bestparams = lsq_fit[0]
            covar = lsq_fit[1]
            bestchisq = errfunc(bestparams, *fitargs)
            ii = 0 # Re-start the burn-in.
            #pos[prob < np.median(prob)] = bestparams
        badpos = (prob < np.median(prob))
        if (pos[True-badpos].std(0) <= 0).any():
            goodpos_unc = np.vstack((np.abs(bestparams / 50.), pos[True-badpos].std(0))).max(0)
            pos[badpos] = np.random.normal(bestparams, goodpos_unc, (badpos.sum(), ndim))
        else:
            pos[badpos]  = np.random.multivariate_normal(bestparams, np.cov(pos[True-badpos].transpose()), badpos.sum())

    pos[badpos] = bestparams

    # Run main MCMC run:
    #pdb.set_trace()
    print str(KIC)+" running initial MCMC"
    pos, prob, state = sampler.run_mcmc(pos, 2*nstep)
    
    if test==1:
        pl.PlotLC(lccut)
        p.plot(np.arange(lccut[0, 0], lccut[-1, 0], 0.001), modelmonotransit(bestparams, np.arange(lccut[0, 0], lccut[-1, 0], 0.001)))
        p.title('New Best Fit post-MCMC1 with'+str(bestparams))
        p.pause(60)
        p.clf()
    
    print 'pos results after second mcmc:'
    print 'Badpos identified '+str(np.shape(badpos))+' positions with probs less than the median prob'
    print str(np.median(pos[:, 0]))+' <median | Tcen | std > '+str(np.std(pos[:, 0]))
    print str(np.median(pos[:, 1]))+' <median | b | std > '+str(np.std(pos[:, 1]))
    print str(np.median(pos[:, 2]))+' <median | v | std > '+str(np.std(pos[:, 2]))
    print str(np.median(pos[:, 3]))+' <median | p | std > '+str(np.std(pos[:, 3]))
    print str(np.median(pos[:, 4]))+' <median | F0 | std > '+str(np.std(pos[:, 4]))
    print str(np.median(pos[:, 5]))+' <median | u1 | std > '+str(np.std(pos[:, 5]))
    print str(np.median(pos[:, 6]))+' <median | u2 | std > '+str(np.std(pos[:, 6]))
    
    pos=FixingExtent(pos)
    
    sampler.reset()
    steps_taken, nbetter = 0, 0
    while steps_taken < nstep:
        pos, prob, state = sampler.run_mcmc(pos, 1)
        steps_taken += 1
        if (bestchisq + 2*max(prob)) > ftol and nbetter<5000: # Found a better fit! Optimize:
            print "Found a better fit; re-starting MCMC... (%1.8f, %1.8f)" % (bestchisq, (bestchisq + 2*max(prob)))
            #pdb.set_trace()
            bestparams = pos[(prob==prob.max()).nonzero()[0][0]].copy()
            lsq_fit = optimize.leastsq(devfuncup, bestparams, args=fitargs, full_output=True, xtol=xtol, ftol=1e-10)
            bestparams = lsq_fit[0]
            covar = lsq_fit[1]
            bestchisq = errfunc(bestparams, *fitargs)
            steps_taken = 0 # Re-start the MCMC
            sampler.reset()
            pos[prob<np.median(prob)] = bestparams
            nbetter+=1
    print 'pos results after third mcmc:'
    print 'Badpos identified '+str(np.shape(badpos))+' positions with probs less than the median prob'
    print str(np.median(pos[:, 0]))+' <median | Tcen | std > '+str(np.std(pos[:, 0]))
    print str(np.median(pos[:, 1]))+' <median | b | std > '+str(np.std(pos[:, 1]))
    print str(np.median(pos[:, 2]))+' <median | v | std > '+str(np.std(pos[:, 2]))
    print str(np.median(pos[:, 3]))+' <median | p | std > '+str(np.std(pos[:, 3]))
    print str(np.median(pos[:, 4]))+' <median | F0 | std > '+str(np.std(pos[:, 4]))
    print str(np.median(pos[:, 5]))+' <median | u1 | std > '+str(np.std(pos[:, 5]))
    print str(np.median(pos[:, 6]))+' <median | u2 | std > '+str(np.std(pos[:, 6]))
    
    pos=FixingExtent(pos)

    # Test if MCMC found a better chi^2 region of parameter space:
    mcmc_params = sampler.flatchain[np.nonzero(sampler.lnprobability.ravel()==sampler.lnprobability.ravel().max())[0][0]]
    mcmc_fit = optimize.leastsq(devfuncup, mcmc_params, args=fitargs, full_output=True, xtol=xtol, ftol=1e-10)
    if errfunc(mcmc_fit[0], *fitargs) < errfunc(bestparams, *fitargs):
        bestparams = mcmc_fit[0]
    else:
        pass
    
    lsq_fit = optimize.leastsq(devfuncup, bestparams, args=fitargs, full_output=True, xtol=xtol, ftol=1e-10)
    bestparams = lsq_fit[0]
    covar = lsq_fit[1]
    bestchisq = errfunc(bestparams, *fitargs)
    
    finalmodel = modelmonotransit(bestparams, fitargs[1])
    print str(KIC)+" finished MCMC"
    return lsq_fit, sampler, weights, finalmodel, StarDat,  lccut


def RunGP(KIC, guess, nstep=20000, StarDat=[], lc=[], test=1):
    '''
    INPUTS:
    KIC as EPIC (K2) or KIC (Kepler) identifier
    guess as list of [Tcen, Tdur, depth]
    nstep: number of steps in MCMC (default 20000)
    StarDat in format Ts,eTs1,eTs2,Rs,eRs1,eRs2,Ms,eMs1,eMs2.
    If stardat empty, looks for stellar parameter estimates from EPIC/KIC catalogue
    lc is input lightcurve in format time, normalised flux and flux errors. If [], gets the lightcurve from either a directory or online
    test displays extra plots and text during MCMC run
    '''
    import planetlib;reload(planetlib);from planetlib import *
    #Where guess is Tcen (d), Tdur (d) and depth (frac)
    if lc==[]:
        lc=getKeplerLC(KIC)
    if guess==[]:
        guess=FindTransitManual(kic, lc, cut=25.0)

    if StarDat==[]:
        StarDat=getStarDat(KIC)

    #Getting Quadratic Limb Darkening Paramters from Temperature:
    print str(KIC)+": Temperature and errors: "+str(StarDat[0])
    LD=getKeplerLDs(StarDat[0])
    if str(int(KIC)).zfill(9)[0]=='2':
        #Liminiting errors to 150K in temperature
        StarDat[1]=150 if StarDat[1]<150 else StarDat[1]
        StarDat[2]=150 if StarDat[2]<150 else StarDat[2]
    LDRange=np.array([getKeplerLDs(StarDat[0]+StarDat[1]), getKeplerLDs(StarDat[0]-StarDat[2])])

    #Checking for previous files
    NoPrevious=True
    if path.isfile(Namwd+'/Outputs/'+"sampler.npy"):
        #Found previous file. Using this instead of guess
        NoPrevious=False
        sams=np.load(Namwd+'/Outputs/'+"sampler.npy")
        sams[:, 1]=abs(sams[:, 1])
        params=np.median(sams[-4000:, :], axis=0)
        Tdur=(2*(1+params[3])*np.sqrt(1-(params[1]/(1+params[3]))**2))/params[2]
        Tdur=CalcTdur(np.median(sams[:,2]),np.median(sams[:,1]),np.median(sams[:,3]))
        Tcen=params[0]
        ratio=params[2]
        #Taking last 4000 values in case previous run was poorly burned in
        if len(sams[0,:])==8:
            #Checking if old files are in the same format, else forcing lntau and lna to be zero
            bestparams=params[0:4]+params[5:]+[0.0,0.0]
            #Using GP parameters already
        else:
            #Only 7 params- using old school params. Modifying...
            bestparams=params
        print 'Found Old Params for '+str(KIC)
    else:
        NoPrevious=True
        Tcen=guess[0]
        Tdur=guess[1]
        ratio=guess[2]**0.5
        params=[Tcen, 0.4, CalcVel(Tdur, 0.4, ratio), ratio, LD[0],  LD[1],0.0,0.0]
        bestparams=np.array(params, copy=True)

    #Getting Lightcurve
    print lc
    lc=lc[np.where(abs(lc[:, 0]-Tcen)<Tdur*15.0)]
    #SHORTENED FOR TESTING. UNSHORTEN FOR ACTUAL MODELLING:
    lccut=lc[np.where(abs(lc[:, 0]-Tcen)<Tdur*7.0)]
    print lccut

    if test==1:
        PlotLC(lccut)
        p.plot(np.arange(lccut[0, 0], lccut[-1, 0], 0.001), modelmonotransitGP(params, np.arange(lccut[0, 0], lccut[-1, 0], 0.001)))
        p.title('Initial Fit with'+str(params))
        #p.pause(5)
        #p.clf()

    '''
        Params are:
        the time of conjunction for each individual transit (Tc),  0.1
        the impact parameter (b = a cos i/Rstar)  0.5
        vel -- scalar. planetary perpendicular velocity (in units of stellar radii per day) 1
        planet-to-star radius ratio (Rp/Rstar),  0.03
        the limb-darkening parameters u1 and u2   0.1
        out-of-transit GP fit params ln(tau), ln(a)
    '''
    bestparams=np.array(params, copy=True)
    #For each value in params
    #Last two values now gaussian priors for limb darkening params:
    uniformprior=[[bestparams[0]-2*Tdur, bestparams[0]+2*Tdur], [-1.2, 1.2], [0.0, CalcVel(Tdur*0.95, 0.0, 0.3)], [0, 0.3], [LD[0], np.max(abs(LD[0]-LDRange[:, 0]))], [LD[1], np.max(abs(LD[1]-LDRange[:, 1]))],[-5,5],[-5,5]]

    print uniformprior
    print params
    ndim = len(params)
    covar = np.zeros((ndim, ndim), dtype=float)
    diag=np.zeros((ndim), dtype=float)
    for ii in range(ndim):
        covar[ii,ii] = 0.35*(abs(bestparams[ii]-uniformprior[ii][0])+abs(bestparams[ii]-uniformprior[ii][1]))
        diag[ii]=0.35*(abs(bestparams[ii]-uniformprior[ii][0])+abs(bestparams[ii]-uniformprior[ii][1]))
    print diag

    goodind = np.isfinite(lccut[:, 1])
    weights = np.array(lccut[:, 2]**-2, copy=True)
    fitargs = (lccut[:, 0], lccut[:, 1], lccut[:,2], uniformprior) #time, NL, NP, errscale, smallplanet, svs, data, weights, fitkw)
    #fitargs = (modelmonotransit, lccut[:, 0], lccut[:, 1], lccut[:, 2], fitkw)
    xtol=1e-12
    ftol=1e-10
    if test==1:
        print 'Initial params: '+str(params)
        p.pause(1)
        print 'doing lsq fit with dvfuncup:'
    '''
    if NoPrevious:
        lsq_fit = optimize.minimize(lnprobfunc2, bestparams, args=fitargs)
        #optimize.minimize(lnprobfunc2, bestparams, args=fitargs, method='Nelder-Mead')#, diag=0.4*diag)
        bestparams = lsq_fit['x']
        print params/bestparams
        if test==1:
            #pl.PlotLC(lccut)
            p.plot(np.arange(lccut[0, 0], lccut[-1, 0], 0.001), modelmonotransit(bestparams, np.arange(lccut[0, 0], lccut[-1, 0], 0.001)))
            #p.title('New Best Fit with'+str(bestparams))
            p.pause(1)
        #lsq_fit = optimize.minimize(lnprobfunc2,  bestparams, args=fitargs)#, diag=0.2*diag)
        #bestparams = lsq_fit['x']
        #print params/bestparams
        if test==1:
            #PlotLC(lccut)
            p.plot(np.arange(lccut[0, 0], lccut[-1, 0], 0.001), modelmonotransit(bestparams, np.arange(lccut[0, 0], lccut[-1, 0], 0.001)))
            #p.title('New Best Fit with'+str(bestparams))
            p.pause(1)
            '''
#        lsq_fit = optimize.fmin(lnprobfunc2, bestparams, args=fitargs)#, diag=0.2*diag)
#        bestparams = lsq_fit
#        print params/bestparams
#        print bestparams
#        if test==1:
#            #PlotLC(lccut)
#            p.plot(np.arange(lccut[0, 0], lccut[-1, 0], 0.001), modelmonotransit(bestparams, np.arange(lccut[0, 0], lccut[-1, 0], 0.001)))
#            #p.title('New Best Fit with'+str(bestparams))
#            p.pause(5)
#            p.clf()

    bestchisq = lnlikeGP(bestparams, *fitargs[:-1])
    #Setting parameters as defaults from Ian.transit

    nwalkers =20 * ndim
    nthread=2
    #nstep=700

    #print 'params:'
    print str(KIC)+": parameters:"+str(bestparams)
    #print (bestparams/100.)**2
    # Initialize sampler:
    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprobGP, args=fitargs, threads=4)
    # Pick walker starting positions, excluding bad points:
    #print covar
    #print np.shape(covar)
    #print 'Covar ^. p0 vv'

    p0 = np.random.multivariate_normal(bestparams, covar, nwalkers*5)
    badp0 = ((abs(p0[:,1]) >1.5) + (p0[:,2] < 0) + (p0[:,3] < 0) + (p0[:,4] < 0))
    #print 'Number of bad p0s: '+str(len(np.nonzero(True-badp0)[0]))+' Number of p0s:'+str(len(p0[0]))
    p0 = np.vstack((bestparams, p0[np.nonzero(True-badp0)[0][0:nwalkers-1]]))
    #print 'Number of bad p0s: '+str(len(np.nonzero(True-badp0)[0]))+' Number of p0s:'+str(len(p0[0]))
    #print p0
    # Run burn-in; exclude and remove bad walkers:
    pos = p0
    #if test==1:
    print 'pos results before first mcmc:'
    print 'Badpos identified '+str(np.shape(badp0))+' positions with probs less than the median prob'
    print str(np.median(pos[:, 0]))+' <median | Tcen | std > '+str(np.std(pos[:, 0]))
    print str(np.median(pos[:, 1]))+' <median | b | std > '+str(np.std(pos[:, 1]))
    print str(np.median(pos[:, 2]))+' <median | v | std > '+str(np.std(pos[:, 2]))
    print str(np.median(pos[:, 3]))+' <median | p | std > '+str(np.std(pos[:, 3]))
    print str(np.median(pos[:, 4]))+' <median | u1 | std > '+str(np.std(pos[:, 4]))
    print str(np.median(pos[:, 5]))+' <median | u2 | std > '+str(np.std(pos[:, 5]))
    print str(np.median(pos[:, 6]))+' <median | a | std > '+str(np.std(pos[:, 6]))
    print str(np.median(pos[:, 7]))+' <median | tau | std > '+str(np.std(pos[:, 7]))
    for ii in range(2):
        pos, prob, state = sampler.run_mcmc(pos, np.max([1, (ii+1)*nstep/5]))
        if (bestchisq + 2*np.max(prob)) > ftol: #-2*prob < bestchisq).any(): # Found a better fit! Optimize:
            #if verbose: print "Found a better fit; re-starting MCMC... (%1.8f, %1.8f)" % (bestchisq, (bestchisq + 2*max(prob)))
            print str(KIC)+" - Found a better fit; re-starting MCMC..."
            #pdb.set_trace()
            bestparams = pos[(prob==prob.max()).nonzero()[0][0]].copy()
            lsq_fit = optimize.leastsq(lnlikeGP, bestparams, args=fitargs, full_output=True, xtol=xtol, ftol=ftol)
            bestparams = lsq_fit[0]
            covar = lsq_fit[1]
            bestchisq = lnlikeGP(bestparams, *fitargs[:-1])
            ii = 0 # Re-start the burn-in.
            #pos[prob < np.median(prob)] = bestparams
        badpos = (prob < np.median(prob))
        if (pos[True-badpos].std(0) <= 0).any():
            goodpos_unc = np.vstack((np.abs(bestparams / 50.), pos[True-badpos].std(0))).max(0)
            pos[badpos] = np.random.normal(bestparams, goodpos_unc, (badpos.sum(), ndim))
        else:
            pos[badpos]  = np.random.multivariate_normal(bestparams, np.cov(pos[True-badpos].transpose()), badpos.sum())

    pos[badpos] = bestparams

    # Run main MCMC run:
    #pdb.set_trace()
    print str(KIC)+" running initial MCMC"
    pos, prob, state = sampler.run_mcmc(pos, 2*nstep)

    if test==1:
        PlotLC(lccut)
        p.plot(np.arange(lccut[0, 0], lccut[-1, 0], 0.001), modelmonotransitGP(bestparams, np.arange(lccut[0, 0], lccut[-1, 0], 0.001)))
        p.title('New Best Fit post-MCMC1 with'+str(bestparams))
        p.pause(60)
        p.clf()

    print 'pos results after second mcmc:'
    print 'Badpos identified '+str(np.shape(badpos))+' positions with probs less than the median prob'
    print str(np.median(pos[:, 0]))+' <median | Tcen | std > '+str(np.std(pos[:, 0]))
    print str(np.median(pos[:, 1]))+' <median | b | std > '+str(np.std(pos[:, 1]))
    print str(np.median(pos[:, 2]))+' <median | v | std > '+str(np.std(pos[:, 2]))
    print str(np.median(pos[:, 3]))+' <median | p | std > '+str(np.std(pos[:, 3]))
    print str(np.median(pos[:, 4]))+' <median | u1 | std > '+str(np.std(pos[:, 4]))
    print str(np.median(pos[:, 5]))+' <median | u2 | std > '+str(np.std(pos[:, 5]))
    print str(np.median(pos[:, 6]))+' <median | tau | std > '+str(np.std(pos[:, 6]))
    print str(np.median(pos[:, 7]))+' <median | a | std > '+str(np.std(pos[:, 7]))

    pos=FixingExtent(pos)

    sampler.reset()
    steps_taken, nbetter = 0, 0
    print bestparams
    while steps_taken < nstep:
        pos, prob, state = sampler.run_mcmc(pos, 1)
        steps_taken += 1
        if (bestchisq + 2*max(prob)) > ftol and nbetter<5000: # Found a better fit! Optimize:
            print "Found a better fit; re-starting MCMC... (%1.8f, %1.8f)" % (bestchisq, (bestchisq + 2*max(prob)))
            #pdb.set_trace()
            bestparams = pos[(prob==prob.max()).nonzero()[0][0]].copy()
            lsq_fit = optimize.leastsq(lnlikeGP, bestparams, args=fitargs, full_output=True, xtol=xtol, ftol=1e-10)
            bestparams = lsq_fit[0]
            covar = lsq_fit[1]
            bestchisq = errfunc(bestparams, *fitargs)
            steps_taken = 0 # Re-start the MCMC
            sampler.reset()
            pos[prob<np.median(prob)] = bestparams
            nbetter+=1
    print 'pos results after third mcmc:'
    print 'Badpos identified '+str(np.shape(badpos))+' positions with probs less than the median prob'
    print str(np.median(pos[:, 0]))+' <median | Tcen | std > '+str(np.std(pos[:, 0]))
    print str(np.median(pos[:, 1]))+' <median | b | std > '+str(np.std(pos[:, 1]))
    print str(np.median(pos[:, 2]))+' <median | v | std > '+str(np.std(pos[:, 2]))
    print str(np.median(pos[:, 3]))+' <median | p | std > '+str(np.std(pos[:, 3]))
    print str(np.median(pos[:, 4]))+' <median | u1 | std > '+str(np.std(pos[:, 5]))
    print str(np.median(pos[:, 5]))+' <median | u2 | std > '+str(np.std(pos[:, 6]))

    pos=FixingExtent(pos)

    # Test if MCMC found a better chi^2 region of parameter space:
    mcmc_params = sampler.flatchain[np.nonzero(sampler.lnprobability.ravel()==sampler.lnprobability.ravel().max())[0][0]]
    mcmc_fit = optimize.leastsq(devfuncup, mcmc_params, args=fitargs, full_output=True, xtol=xtol, ftol=1e-10)
    if errfunc(mcmc_fit[0], *fitargs) < errfunc(bestparams, *fitargs):
        bestparams = mcmc_fit[0]
    else:
        pass

    lsq_fit = optimize.leastsq(devfuncup, bestparams, args=fitargs, full_output=True, xtol=xtol, ftol=1e-10)
    bestparams = lsq_fit[0]
    covar = lsq_fit[1]
    bestchisq = errfunc(bestparams, *fitargs)

    finalmodel = modelmonotransit(bestparams, fitargs[1])
    print str(KIC)+" finished MCMC"
    return lsq_fit, sampler, weights, finalmodel, StarDat,  lccut


def Pmin(lc, Tcen, Tdur):
    #Calculating minimum period from the lightcurve
    return np.max(abs(Tcen-lc[:, 0]))-Tdur

'''
def TrainGP(lc,Tcen,Vmag):
    #This optimizes the gaussian process on out-of-transit data. This is then held with a gaussian prior during modelling
    #Args:
        #lc: lightcurve
        #Tcen: Central transit time

    #Returns:
    #    a, tau: Squared Exponential kernel hyperparameters
    import scipy.optimize as op
    lcs=lc[np.where((lc[:,0]-Tcen)>0.4)[0],:]

    # Define the objective function (negative log-likelihood in this case).
    #import george
    WNmag14 = 0.001 #White Noise at 14th magnitude. <<<CHECK THIS>>
    wn=WNmag14/np.sqrt(10**((14-Vmag)/2.514)) #Calculating White Noise from sqrt flux (eg assuming poisson)
    a,tau=1.0,0.3
    kernel=a*(george.kernels.ExpSquaredKernel(tau))
    gp = george.GP(kernel, mean=np.mean(lcs[:,1]), fit_mean=True, white_noise=wn, fit_white_noise=True)
    print lcs
    gp.compute(lcs[:,0],lcs[:,2])
    print(gp.lnlikelihood(lcs[:,1]))
    print(gp.grad_lnlikelihood(lcs[:,1]))
    gp.compute(lcs[:,0],lcs[:,2])
    # Print the initial ln-likelihood.
    print(gp.lnlikelihood(lcs[:,1]))
    # Run the optimization routine.
    p0 = gp.get_vector()
    results = op.minimize(nll, p0,args=(gp,lcs[:,1]), jac=grad_nll, method="L-BFGS-B")

    # Update the kernel and print the final log-likelihood.
    gp.set_vector(results.x)
    print(results)

    return gp, results.x[0], results.x[1], gp.lnlikelihood(lcs[:,1])

'''


def nll(p,gp,y):
    gp.set_vector(p)
    ll = gp.lnlikelihood(y, quiet=True)
    return -ll if np.isfinite(ll) else 1e25

# And the gradient of the objective function.
def grad_nll(p,gp,y):
    gp.set_vector(p)
    return -gp.grad_lnlikelihood(y, quiet=True)

def FixingExtent(pos):
    #Finding out if the MCMC has converged on a single value anywhere, and fixing this to add artificial variation
    NoExtent=np.where(np.std(pos, axis=0)<1e-6)[0]
    if len(NoExtent)>0:
        for p in NoExtent:
            #Finding out how many times less than 1e-6 the standard deviation is, and multiplying by that difference to get it back to acceptable levels
            ratiobelow=1e-6/np.std(pos[:, p])
            pos[:, p]*=np.random.normal(1.5*ratiobelow, 0.5*ratiobelow, len(pos[:, p]))
    return pos

def CalcTdur(vel, b, p):
    '''Caculates a velocity (in v/Rs) from the input transit duration Tdur, impact parameter b and planet-to-star ratio p'''
    # In Rs per day
    return (2*(1+p)*np.sqrt(1-(b/(1+p))**2))/vel
    
def CalcVel(Tdur, b, p):
    '''Caculates a velocity (in v/Rs) from the input transit duration Tdur, impact parameter b and planet-to-star ratio p'''
    # In Rs per day
    return (2*(1+p)*np.sqrt(1-(b/(1+p))**2))/Tdur

def VelToOrbit(Vel, Rs, Ms, ecc=0, omega=0):
    '''Takes in velocity (in units of stellar radius), Stellar radius estimate and (later) eccentricity & angle of periastron.
    Returns Semi major axis (AU) and period (days)'''
    import me.constants as c
    Rs=Rs*c.Rsun if Rs<5 else Rs
    Ms=Ms*c.Msun if Ms<5 else Ms
    SMA=(c.G*Ms)/((Vel*Rs/86400.)**2)
    Per=(2*np.pi*SMA)/(Vel*Rs/86400)
    return SMA/c.AU, Per

def PerToVel(Period, Rs, Ms):
    return ((2*np.pi*6.67e-11*Ms*1.96e30)/(Period*86400*(Rs*695000000)**3))**(1/3.)

def PlotMCMC(params,  EPIC, sampler, lc, KepName=''):
    import pylab as p
    import triangle
    if type(sampler)!=np.ndarray:
        samples = sampler.chain[:, -10000:, :].reshape((-1, len(params)))
    else:
        samples=sampler
    #Turning b into absolute...
    samples[:,1]=abs(samples[:,1])
    #np.savetxt('Kep103B.txt', samples)
    p.figure(1)
    fig = triangle.corner(samples, labels=["$T_{c}$","$b$","$v$","$Rp/Rs$","$u1$","$u2$","$tau$","$a$"],quantiles=[0.16, 0.5, 0.84], plot_datapoints=False)
    #Plotting model in top right
    p.subplot(7,7,10).axis('off')
    if KepName=='':
        if str(int(EPIC)).zfill(9)[0]=='2':
            KepName='EPIC'+str(EPIC)
        else:
            KepName='KIC'+str(EPIC)
    p.title(KepName, fontsize=22)
    ax = p.subplot2grid((7,7), (0, 4), rowspan=2, colspan=3)
    #p.errorbar(lc[:, 0], lc[:, 1], yerr=lc[:, 1], fmt='.',color='#EEEEEE')
    #p.plot(lc[:, 0], lc[:, 1], '.',color='#')
    modelfits=PlotModel(lc,  samples,scale=3)
    #plotting residuals:
    ax = p.subplot2grid((7,7), (2, 4), rowspan=1, colspan=3)
    modelfits=PlotModel(lc,  samples, modelfits, residuals=True, scale=3)
    if os.path.exists('/home/astro/phrnbe/SinglesSC/TestMCMCs/Pcorner_fit_'+str(EPIC)+'Aug.pdf'):
        if os.path.exists('/home/astro/phrnbe/SinglesSC/TestMCMCs/Pcorner_fit_'+str(EPIC)+'2Aug.pdf'):
            fname='/home/astro/phrnbe/SinglesSC/TestMCMCs/Pcorner_fit_'+str(EPIC)+'3Aug.pdf'
        else:
            fname='/home/astro/phrnbe/SinglesSC/TestMCMCs/Pcorner_fit_'+str(EPIC)+'2Aug.pdf'
    else:
        fname='/home/astro/phrnbe/SinglesSC/TestMCMCs/Pcorner_fit_'+str(EPIC)+'Aug.pdf'
    p.savefig(fname,Transparent=True,dpi=300)
    return modelfits
    
def GetVel(sampler, StarDat, nsamp):
    #Taking random Nsamples from samples to put through calculations
    #Need to form assymetric gaussians of Star Dat parameters if not equal
    import me.constants as c
    Rstardist=np.random.normal(StarDat[3], (StarDat[5]+StarDat[4])/2, nsamp)
    Mstardist=np.random.normal(StarDat[6], (StarDat[7]+StarDat[8])/2, nsamp)
    #Rstardist2=np.hstack((np.sort(Rstardist[:, 0])[0:int(nsamp/2)], np.sort(Rstardist[:, 1])[int(nsamp/2):] ))
    Rplans, Ps, Smas, Krvs, Mps=[], [], [], [], []
    for n in range(nsamp):
        rn=np.random.randint(len(sampler[:,3]))
        Rplans+=[(sampler[rn, 3]*c.Rsun*Rstardist[n])/c.Rjup]
        sma, P = VelToOrbit(sampler[rn, 2], Rstardist[n], Mstardist[n])
        Ps+=[P/86400.]
        Smas+=[sma]
        #Krv = ((2.*np.pi*6.67e-11)/P)**(1./3.)*((Mp*np.sin(i))/(Ms**(2./3.)))) 
        Mp=(PlanetRtoM((sampler[rn, 3]*c.Rsun*Rstardist[n])/6371000.0))*5.6e24
        Mps+=[Mp]
        Krvs+=[((2.*np.pi*6.67e-11)/P)**(1./3.)*((Mp)/((1.96e30*Mstardist[n])**(2./3.)))]
    #Putting gaussians through
    #Rtests=np.random.rand
    #.argsort()[int(np.round(0.16*5000))]
    sigs=[6.76676416,   18.39397206,   50.,81.60602794,93.23323584]
    #print np.percentile(np.array(Krvs), sigs)
    #print np.percentile(np.array(Mps)/c.Mjup, sigs)
    #print np.percentile(np.array(Rplans), sigs)
    return np.percentile(np.array(Rplans), sigs),  np.percentile(np.array(Ps), sigs), np.percentile(np.array(Smas), sigs), np.percentile(np.array(Krvs), sigs)
    '''
def OmegaInRange(Om,e):
    '''#transit probability defined by eccentricity and true anomaly.
    #Returns True when random number generated happens to be below the local probability density function as defined by Barnes in eqn 6 (arxiv.org/abs/0708.0243).
    '''
    prob=(2*695500000*(1+e*np.cos(Om)))/(0.2*1.49e11*(1-e**2))
    prob=1 if prob>1 else prob
    if np.random.random()<prob:
        return True
    else:
        return False


def ApplyEccentricityDist(Vdist):
    '''#Creates delta velocity distribution from 'general' eccebtricity distribution of exoplanets via a beta function (Kipping arxiv.org/abs/1306.4982v2)
    #Returns a 20,000-long array of values in distribution around median (~1.0, where Vcirc==Vreal).
    #Then convolves this distribtuion with the input velocity distribution from the mcmc.
    #To be updated
    '''
    from scipy.stats import beta
    while len(outVel)<20000:
        e=beta.ppf(np.random.random(),0.711,2.57)
        Om=np.random.random()*2*np.pi
        if OmegaInRange(Om,e):
            v=(1+e*np.cos(Om))/np.sqrt(1-e**2)
            outVel+=[v]
    conv = np.convolve(Vdist, np.array(outVel))
'''

def PlotModel(lccut, sampler, models='', residuals=False, scale=1, nx=10000):
    '''This plots the single transit, with the uncertainty area of the fit (scaled by ''scale'' parameter for ease of view)
    If residuals, the model is subtracted with only residuals left.
    #Inputs:
    lccut - lightcurve cut around transit
    sampler - MCMC output
    models - percentiles of the best-fit model for each timestamp
    residuals - specifies whether to plot residuals or normal
    scale - allows the 'filled' 1-sigma area to be scaled by a factor for ease of view
    #Outputs:
    models (in columns of -2.-1,0,1 and 2 -sigma uncertainties) generated by sampling nx (10000) random samples from the MCMC output
    '''
    #Getting the times that are not in t (eg due to time jumps)
    t=np.arange(lccut[0,0],lccut[-1,0]+0.01,0.020431700249901041)

    #Generating model fit regions
    if len(models)==0:
        #Getting models by looping threw samples and adding flux for each to large array
        modelouts=np.zeros((len(t), nx))
        idx=np.random.randint(len(sampler[:,0]), size=nx)
        for i in range(nx):
            modelouts[:,i]=modelmonotransit(sampler[idx[i],:],t)
        # Turning this nx*nt array into a 5*t array of-2,-1,0,+1 & +2 sigma models
        modelfits=np.percentile(modelouts,[6.76676416,   18.39397206,   50., 81.60602794,93.23323584],axis=1)
        modelfits=np.swapaxes(modelfits, 1, 0)
    else:
        modelfits=models
    
    flux=lccut[:, 1]
    newmodelfits=np.copy(modelfits)
    if residuals:
        #Subtracting bestfit model from both flux and model to give residuals
        newmodelfits=modelfits-np.tile(modelfits[:,2], (5, 1)).swapaxes(0, 1) #subtracting median fit
        flux-=modelfits[:, 2][(np.round((lccut[:,0]-lccut[0,0])/0.020431700249901041)).astype(int)]
    #p.xlim([t[np.where(redfits[:,2]==np.min(redfits[:,2]))]-1.6, t[np.where(redfits[:,2]==np.min(redfits[:,2]))]+1.6])
    
    #Plotting 1-sigma error region
    p.fill(np.hstack((t,t[::-1])),np.hstack((newmodelfits[:,2]-(newmodelfits[:,2]-newmodelfits[:,1]),(newmodelfits[:,2]+(newmodelfits[:,3]-newmodelfits[:,2]))[::-1])),'#33BBFF', linewidth=0,label='1-sigma uncertainties scaled by '+str(scale*100)+'%')
    
    #Plotting data
    p.errorbar(lccut[:, 0], flux, yerr=lccut[:, 2], fmt='.',color='#999999')
    p.plot(lccut[:, 0], flux, '.',color='#333399')
    p.plot(t,newmodelfits[:,2],'-',color='#003333',linewidth=2.0,label='Median model fit')
    
    #if not residuals:
        #Putting title on upper (non-residuals) graph
        #p.title('Best fit model')
        #p.legend()
    return modelfits

def StartSingleRun(kic):
    '''
    This script uses the KOI data table and associated parameters to start a 'Namaste' run.
    Finding the transit is still required
    '''
    kic=int(kic)
    AllKicData=KicData(kic)
    lccut, TransData=FindTransitManual(kic)
    savedlcname=Sourcedir+'KeplerFits/KOI'+str(AllKicData['kepoi_name'].values[0])+'/'+'Transit_LC_at_'+str(TransData[0])+'_lc.txt'
    np.savetxt(savedlcname, lccut)
    StarDat=[AllKicData['koi_steff'].values[0], AllKicData['koi_steff_err1'].values[0],  AllKicData['koi_steff_err2'].values[0], AllKicData['koi_srad'].values[0], AllKicData['koi_srad_err1'].values[0],  AllKicData['koi_srad_err2'].values[0], AllKicData['koi_smass'].values[0], AllKicData['koi_smass_err1'].values[0],  AllKicData['koi_smass_err2'].values[0]]
    #Currently just fudging it to run the other python script from the command line
    print 'python McmcSingles.py \''+str(kic)+', '+savedlcname+', '+str(TransData).replace(' ','')+' , 28000, '+str(StarDat).replace(' ','')+'\'' #['+TransData[0]+', '+TransData[1]+', '+TransData[2]+']


def SaveOutputs(KIC, lsq_fit, weights, finalmodel, lc, samplercut, Rps, Ps, As, StarDat, sigs=np.array([2.2750131948178987, 15.865525393145707, 50.0, 84.13447460685429, 97.7249868051821])):
    print 'Saving '+str(KIC)+' outputs to file'
    np.save(Namwd+'/Outputs/'+str(KIC)+"lsq_fitAug", lsq_fit)
    np.save(Namwd+'/Outputs/'+str(KIC)+"weightsAug", weights)
    np.save(Namwd+'/Outputs/'+str(KIC)+"finalmodelAug", finalmodel)
    np.save(Namwd+'/Outputs/'+str(KIC)+"lightcurveAug", lc)
    np.save(Namwd+'/Outputs/'+str(KIC)+"samplerAug", samplercut)
    #Tcen, b, v, p0, F0, u1, u2, Rp, P, sma, Ts, Rs, Ms - 1- and 2-sigma boundaries for each.
    params=np.vstack((np.percentile(samplercut[:, 0], sigs), np.percentile(samplercut[:, 1], sigs), np.percentile(samplercut[:, 2], sigs), np.percentile(samplercut[:, 3], sigs), np.percentile(samplercut[:, 4], sigs), np.percentile(samplercut[:, 5], sigs), np.percentile(samplercut[:, 6], sigs), Rps, Ps, As, np.array([StarDat[0]-2*StarDat[1], StarDat[0]-StarDat[1], StarDat[0], StarDat[0]+StarDat[2], StarDat[0]+2*StarDat[2]]), np.array([StarDat[3]-2*StarDat[4], StarDat[3]-StarDat[4], StarDat[3], StarDat[3]+StarDat[5], StarDat[3]+2*StarDat[5]]), np.array([StarDat[6]-2*StarDat[7], StarDat[6]-StarDat[7], StarDat[6], StarDat[6]+StarDat[8], StarDat[6]+2*StarDat[8]]) ))

    np.savetxt(Namwd+'/Outputs/'+str(KIC)+"params.txt", params)
    #Putting parameters in a master file of all Namaster runs
    filename=(Namwd+'/Outputs/FullMcmcmOutput.csv')
    if path.exists(filename):
        c = csv.writer(open(filename,'a'))
        c.writerow(list(params))
    else:
        #Writing header
        c = csv.writer(open(filename, "wb"))
        c.writerow(['#KEPID','_','_','T_cen','_','_','_','_','b','_','_','_','_','v','_','_','_','_','p0','_','_','_','_','F0','_','_','_','_','u1','_','_','_','_','u2','_','_','_','_','Rp','_','_','_','_','P','_','_','_','_','A','_','_','_','_','K_rv','_','_','_','_','T_s','_','_','_','_','R_s','_','_','_','_','M_s','_','_','COMEPLTE?','COMMENT?'])
        c.writerow(['#','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig','-2sig','-1sig','med','+1sig','+2sig'])
        c.writerow(list(params))


if __name__ == '__main__':
    #Running from the command line
    #Syntax: python Namaste.py KIC, Tcen, Tdur, depth
    args=sys.argv[1]
    args=args.replace(' ','')
    args=args.split(',')
    print args
    if len(args)<4 or len(args)>6:
        print args
        print 'Only '+str(len(args))+' args detected.'
        print '3 to 5 inputs required (separated by commas in \' \'s :'
        print '(KIC, Tcen, Tdur, depth, nstep)'
    else:
        KIC=int(args[0])
        #lc=getKeplerLC(KIC)
        StarDat=getStarDat(KIC)
        nstep=int(args[-1])
        guess=np.array((args[1:3])).astype(float)
        lsq_fit, sampler, weights, finalmodel, StarDat, lc = RunGP(KIC, guess, nstep, StarDat)
        #Saving outputs to file
        samplercut=sampler.chain[:,-10000:,:].reshape((-1,7))
        #Doing period calculations from velocity distribution
        Rps, Ps, As,  Krvs = GetVel(samplercut, StarDat, 5000)
        print str(KIC)+" - Period of "+str(Ps[3])+" +"+str(Ps[4]-Ps[3])+"/ -"+str(Ps[3]-Ps[2])
        print str(KIC)+" - Semi Major Axis of "+str(As[3])+" +"+str(As[4]-As[3])+"/ -"+str(As[3]-As[2])
        print str(KIC)+" - Radius of "+str(Rps[3])+" +"+str(Rps[4]-Rps[3])+"/ -"+str(Rps[3]-Rps[2])
        SaveOutputs(KIC, lsq_fit, weights, finalmodel, lc, samplercut, Rps, Ps, As, StarDat)
        #Plotting mcmc
        fig=PlotMCMC(lsq_fit[0],  KIC, sampler, lc)
        


